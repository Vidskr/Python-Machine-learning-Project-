{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6060e3ae-feb8-4046-bba8-d810d5643974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03 â€” Advanced ML Models\n",
    "\n",
    "Train advanced gradient boosting models for improved performance:\n",
    "-Logistic Regression \n",
    "-Tuned Random Forest\n",
    "- Gradient Boosting \n",
    "\n",
    "Also includes early hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50bbb8eb-3c92-4a58-9f14-b4e335246e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Advanced Models\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5df7ef9-62a3-4e03-b028-cea991d56767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load processed sparse arrays ===\n",
    "X_train = sparse.load_npz(\"data/processed/X_train.npz\")\n",
    "X_test = sparse.load_npz(\"data/processed/X_test.npz\")\n",
    "y_train = np.load(\"data/processed/y_train.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"data/processed/y_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22c141c-7f4a-45e0-a489-4ce79d82cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree-based models require dense arrays\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe42741-578c-470e-8277-4fca05014259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Logistic Regression Results:\n",
      "Accuracy: 0.8882283580622974\n",
      "ROC-AUC: 0.6524423938513572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     18083\n",
      "           1       0.48      0.02      0.03      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.68      0.51      0.49     20354\n",
      "weighted avg       0.84      0.89      0.84     20354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#  L1 Logistic Regression\n",
    "# =========================\n",
    "\n",
    "lr_l1 = LogisticRegression(\n",
    "    penalty=\"l1\",\n",
    "    solver=\"liblinear\",\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr_l1.fit(X_train_dense, y_train)\n",
    "\n",
    "pred_lr_l1 = lr_l1.predict(X_test_dense)\n",
    "prob_lr_l1 = lr_l1.predict_proba(X_test_dense)[:, 1]\n",
    "\n",
    "print(\"L1 Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr_l1))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, prob_lr_l1))\n",
    "print(classification_report(y_test, pred_lr_l1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "340e2b39-4918-4a76-be72-795afbeef984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest Results:\n",
      "Accuracy: 0.8884248796305394\n",
      "ROC-AUC: 0.6626251723028797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     18083\n",
      "           1       0.00      0.00      0.00      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.44      0.50      0.47     20354\n",
      "weighted avg       0.79      0.89      0.84     20354\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#  Tuned Random Forest\n",
    "# =========================\n",
    "\n",
    "rf_adv = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_adv.fit(X_train_dense, y_train)\n",
    "\n",
    "pred_rf_adv = rf_adv.predict(X_test_dense)\n",
    "prob_rf_adv = rf_adv.predict_proba(X_test_dense)[:, 1]\n",
    "\n",
    "print(\"Tuned Random Forest Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_rf_adv))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, prob_rf_adv))\n",
    "print(classification_report(y_test, pred_rf_adv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6834542-cce1-4590-900f-737f5ff3899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Phase 4.3: Gradient Boosting\n",
    "# =========================\n",
    "\n",
    "gb_adv = GradientBoostingClassifier(\n",
    "    n_estimators=80,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_adv.fit(X_train_dense, y_train)\n",
    "\n",
    "pred_gb_adv = gb_adv.predict(X_test_dense)\n",
    "prob_gb_adv = gb_adv.predict_proba(X_test_dense)[:, 1]\n",
    "\n",
    "print(\"Gradient Boosting Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_gb_adv))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, prob_gb_adv))\n",
    "print(classification_report(y_test, pred_gb_adv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ff354-61e0-4055-a5a5-8370a41c9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Phase 4.4: Model Comparison\n",
    "# =========================\n",
    "\n",
    "results_phase4 = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"L1 Logistic Regression\",\n",
    "        \"Tuned Random Forest\",\n",
    "        \"Gradient Boosting\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, pred_lr_l1),\n",
    "        accuracy_score(y_test, pred_rf_adv),\n",
    "        accuracy_score(y_test, pred_gb_adv)\n",
    "    ],\n",
    "    \"ROC-AUC\": [\n",
    "        roc_auc_score(y_test, prob_lr_l1),\n",
    "        roc_auc_score(y_test, prob_rf_adv),\n",
    "        roc_auc_score(y_test, prob_gb_adv)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_phase4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
